{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import logging\n",
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "\n",
    "# Init the logger.\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "class MotionDetector():\n",
    "\n",
    "    def get_frames_as_ndarray(self, fragment_bytes, one_in_frames_ratio):\n",
    "        '''\n",
    "        Parses fragment_bytes and returns a ratio of available frames in the MKV fragment as\n",
    "        a list of numpy.ndarray's.\n",
    "\n",
    "        e.g: Setting one_in_frames_ratio = 5 will return every 5th frame found in the fragment.\n",
    "        (Starting with the first)\n",
    "\n",
    "        To return all available frames just set one_in_frames_ratio = 1\n",
    "\n",
    "        ### Parameters:\n",
    "\n",
    "            fragment_bytes: bytearray\n",
    "                A ByteArray with raw bytes from exactly one fragment.\n",
    "\n",
    "            one_in_frames_ratio: Str\n",
    "                Ratio of the available frames in the fragment to process and return.\n",
    "\n",
    "        ### Return:\n",
    "\n",
    "            frames: List<numpy.ndarray>\n",
    "            A list of frames extracted from the fragment as numpy.ndarray\n",
    "        \n",
    "        '''\n",
    "\n",
    "        # Parse all frames in the fragment to frames list\n",
    "        frames = iio.imread(io.BytesIO(fragment_bytes), plugin=\"pyav\", index=...)\n",
    "\n",
    "        # Store and return frames in frame ratio of total available \n",
    "        ret_frames = []\n",
    "        for i in range(0, len(frames), one_in_frames_ratio):\n",
    "            ret_frames.append(frames[i])\n",
    "\n",
    "        return ret_frames\n",
    "\n",
    "    def save_frames_as_jpeg(self, ndarray_frames, jpg_file_base_path):\n",
    "        '''\n",
    "        Saves frames as\n",
    "        JPEGs on the local disk.\n",
    "        ### Parameters:\n",
    "\n",
    "        ndarray_frames: List<numpy.ndarray>\n",
    "            A ByteArray with raw bytes from exactly one fragment.\n",
    "\n",
    "        ### Return\n",
    "        jpeg_paths : List<Str>\n",
    "            A list of file paths to the saved JPEN files. \n",
    "        \n",
    "        '''\n",
    "\n",
    "        # Write frames to disk as JPEG images\n",
    "        jpeg_paths = []\n",
    "        for i in range(len(ndarray_frames)):\n",
    "            frame = ndarray_frames[i]\n",
    "            image_file_path = '{}-{}.jpg'.format(jpg_file_base_path, i)\n",
    "            iio.imwrite(image_file_path, frame, format=None)\n",
    "            jpeg_paths.append(image_file_path)\n",
    "        \n",
    "        return jpeg_paths\n",
    "\n",
    "    def pixel_difference(self, frames, threshold=50):\n",
    "        significant_frames = [frames[0]]  # Almacena el primer frame como base\n",
    "        for i in range(1, len(frames)):\n",
    "            diff = np.abs(frames[i].astype(np.int16) - frames[i-1].astype(np.int16))  # Diferencia de píxeles\n",
    "            if np.mean(diff) > threshold:  # Compara con el umbral\n",
    "                significant_frames.append(frames[i])\n",
    "        return significant_frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo para poder procesar los Key frames de forma independiente al flujo para optimizarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # Import for displaying images in Jupyter notebook\n",
    "\n",
    "# Configuración\n",
    "video_paths = [f\"../videos/video{i}.mp4\" for i in range(1, 7)]\n",
    "frame_interval = 30  # Capturar 1 frame cada 30\n",
    "pixel_diff_threshold = 10  # Umbral para considerar que hay movimiento significativo\n",
    "\n",
    "# Procesar cada video\n",
    "for video_path in video_paths:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error al abrir el video: {video_path}\")\n",
    "        continue\n",
    "\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "    key_frame_count = 0\n",
    "    prev_frame = None\n",
    "    significant_frames = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Extraer 1 de cada 30 frames\n",
    "        if frame_count % frame_interval == 0:\n",
    "            print(f\"FRAME {frame_count}\")\n",
    "\n",
    "            key_frame_count +=1\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convertir a escala de grises\n",
    "\n",
    "            if prev_frame is not None:\n",
    "                # Calcular diferencia de píxeles\n",
    "                diff = cv2.absdiff(frame_gray, prev_frame)\n",
    "                mean_diff = np.mean(diff)\n",
    "                print(f\"Media {mean_diff} y Umbral {pixel_diff_threshold}\" )\n",
    "                # Mostrar frame si supera el umbral\n",
    "                if mean_diff > pixel_diff_threshold:\n",
    "                    print(f\"Supera el umbral\")\n",
    "                    plt.imshow(frame, cmap='gray')  # Display grayscale image\n",
    "                    plt.title(f\"Frame {frame_count} - Video: {os.path.basename(video_path)}\")\n",
    "                    plt.show()  # Display the image\n",
    "                    significant_frames.append(frame)\n",
    "\n",
    "            prev_frame = frame_gray  # Actualizar el frame previo\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Información del video procesado\n",
    "    print(f\"Procesado: {video_path}\")\n",
    "    print(f\"Frames totales: {frame_count}\")\n",
    "    print(f\"KEY Frames totales: {key_frame_count}\")\n",
    "    print(f\"Frames significativos detectados: {len(significant_frames)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo empleando SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Configuración\n",
    "video_paths = [f\"../videos/video{i}.mp4\" for i in range(1, 7)]\n",
    "output_dir = \"../frames/ssim_motion/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Umbral de SSIM\n",
    "SSIM_THRESHOLD = 0.87\n",
    "\n",
    "# Función para procesar un video\n",
    "def process_video(video_path, frame_step=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    motion_frames = []  # Lista para guardar frames con movimiento\n",
    "    key_frame = None\n",
    "    frame_count = 0\n",
    "    key_frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Extraer 1 de cada `frame_step` frames\n",
    "        if frame_count % frame_step == 0:\n",
    "            # Convertir el frame a escala de grises\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            key_frame_count += 1\n",
    "            print(f\"FRAME {frame_count}\")\n",
    "\n",
    "            if key_frame is None:\n",
    "                # Primer frame siempre es el key frame\n",
    "                key_frame = gray_frame\n",
    "                motion_frames.append(frame)\n",
    "                continue\n",
    "\n",
    "            # Calcular SSIM con el key frame\n",
    "            score, _ = ssim(key_frame, gray_frame, full=True)\n",
    "            print(f\"Score {score} y Umbral {SSIM_THRESHOLD}\")\n",
    "            if score < SSIM_THRESHOLD:\n",
    "                # Cambio significativo: Guardar el frame actual\n",
    "                motion_frames.append(frame)\n",
    "                key_frame = gray_frame  # Actualizar el key frame\n",
    "\n",
    "        frame_count += 1\n",
    "    print(f\"KEY frames {key_frame_count}\")\n",
    "    cap.release()\n",
    "    return motion_frames\n",
    "\n",
    "# Procesar cada video\n",
    "for video_path in video_paths:\n",
    "    video_name = os.path.basename(video_path).split('.')[0]\n",
    "    motion_frames = process_video(video_path)\n",
    "\n",
    "    print(f\"Video: {video_name}, Motion Frames Detectados: {len(motion_frames)}\")\n",
    "\n",
    "    # Guardar y mostrar los frames con matplotlib\n",
    "    for i, frame in enumerate(motion_frames):\n",
    "        output_path = os.path.join(output_dir, f\"{video_name}_motion_{i}.jpg\")\n",
    "        cv2.imwrite(output_path, frame)\n",
    "\n",
    "        # Mostrar con matplotlib\n",
    "        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Motion Frame {i+1} - {video_name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de Flujo optico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Configuración\n",
    "video_paths = [f\"../videos/video{i}.mp4\" for i in range(1, 4)]\n",
    "\n",
    "# Parámetros del flujo óptico y umbral\n",
    "FRAME_STEP = 30\n",
    "MOTION_THRESHOLD = 2.5  # Ajusta este valor para definir qué nivel de movimiento es significativo\n",
    "\n",
    "def process_video_with_optical_flow(video_path, frame_step=FRAME_STEP):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    motion_frames = []\n",
    "    prev_gray = None\n",
    "    frame_count = 0\n",
    "    key_frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Procesar solo frames seleccionados\n",
    "        if frame_count % frame_step == 0:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            key_frame_count+=1\n",
    "            print(f\"FRAME {key_frame_count}\")\n",
    "            if prev_gray is None:\n",
    "                prev_gray = gray\n",
    "                continue\n",
    "\n",
    "            # Calcular el flujo óptico con Farneback\n",
    "            flow = cv2.calcOpticalFlowFarneback(\n",
    "                prev_gray, gray, None,\n",
    "                pyr_scale=0.5, levels=3, winsize=15,\n",
    "                iterations=3, poly_n=5, poly_sigma=1.2, flags=0\n",
    "            )\n",
    "\n",
    "            # Magnitud del movimiento (norma de los vectores de flujo)\n",
    "            magnitude, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "\n",
    "            # Promedio de la magnitud del movimiento\n",
    "            mean_motion = np.mean(magnitude)\n",
    "            print(f\"MEAN {mean_motion} y Umbral {MOTION_THRESHOLD}\")\n",
    "            if mean_motion > MOTION_THRESHOLD:\n",
    "                # Cambio significativo detectado\n",
    "                motion_frames.append(frame)\n",
    "\n",
    "            # Actualizar el frame previo\n",
    "            prev_gray = gray\n",
    "\n",
    "        frame_count += 1\n",
    "    print(f\"KEY frames {key_frame_count}\")\n",
    "    cap.release()\n",
    "    return motion_frames\n",
    "\n",
    "# Procesar cada video\n",
    "for video_path in video_paths:\n",
    "    video_name = os.path.basename(video_path).split('.')[0]\n",
    "    motion_frames = process_video_with_optical_flow(video_path)\n",
    "\n",
    "    print(f\"Video: {video_name}, Motion Frames Detectados: {len(motion_frames)}\")\n",
    "\n",
    "    # Guardar y mostrar los frames con matplotlib\n",
    "    for i, frame in enumerate(motion_frames):\n",
    "\n",
    "        # Mostrar con matplotlib\n",
    "        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Motion Frame {i+1} - {video_name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame Differencig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Lista de videos\n",
    "video_paths = [f\"../videos/video{i}.mp4\" for i in range(1, 4)]\n",
    "\n",
    "def process_video_with_frame_diff(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    prev_frame = None\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Calcular diferencia de frames\n",
    "        if prev_frame is not None:\n",
    "            diff = cv2.absdiff(prev_frame, gray)\n",
    "            _, diff_thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # Mostrar resultados cada 30 frames\n",
    "            if frame_count % 30 == 0:\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(gray, cmap='gray')\n",
    "                plt.title(\"Frame Original\")\n",
    "                plt.axis(\"off\")\n",
    "                \n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.imshow(diff_thresh, cmap='gray')\n",
    "                plt.title(\"Detección de Movimiento (Frame Differencing)\")\n",
    "                plt.axis(\"off\")\n",
    "                \n",
    "                plt.show()\n",
    "        \n",
    "        # Actualizar el frame previo\n",
    "        prev_frame = gray\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "# Procesar cada video\n",
    "for video in video_paths:\n",
    "    process_video_with_frame_diff(video)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background substraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Lista de videos\n",
    "video_paths = [f\"../videos/video{i}.mp4\" for i in range(1, 4)]\n",
    "\n",
    "# Configuración de background subtraction\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=True)\n",
    "\n",
    "def process_video_with_bg_subtraction(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Aplicar background subtraction\n",
    "        fg_mask = bg_subtractor.apply(gray)\n",
    "        \n",
    "        # Mostrar resultados cada 30 frames\n",
    "        if frame_count % 30 == 0:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(gray, cmap='gray')\n",
    "            plt.title(\"Frame Original\")\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(fg_mask, cmap='gray')\n",
    "            plt.title(\"Detección de Movimiento (BG Subtraction)\")\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            plt.show()\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "# Procesar cada video\n",
    "for video in video_paths:\n",
    "    process_video_with_bg_subtraction(video)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferencia entre difference y BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lista de videos\n",
    "# video_paths = [f\"../videos/video{i}.mp4\" for i in range(1, 4)]\n",
    "video_paths = [f\"../videos/video{i}.mp4\" for i in range(1, 2)]\n",
    "\n",
    "# Configuración de background subtraction\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=True)\n",
    "\n",
    "def process_video_combined(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    prev_frame = None  # Para frame differencing\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % 30 == 0:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # **Frame Differencing**\n",
    "            if prev_frame is not None:\n",
    "                diff = cv2.absdiff(prev_frame, gray)\n",
    "                _, diff_thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)\n",
    "                print(f\"EL umbral es {diff_thresh}\")\n",
    "            else:\n",
    "                diff_thresh = np.zeros_like(gray)\n",
    "\n",
    "            # Actualizar el frame previo\n",
    "            prev_frame = gray\n",
    "\n",
    "            # **Background Subtraction**\n",
    "            fg_mask = bg_subtractor.apply(gray)\n",
    "\n",
    "            # Mostrar resultados cada 30 frames\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            \n",
    "            # Frame Original\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(f\"Frame {frame_count} - Original\")\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            # Frame Differencing\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(diff_thresh, cmap=\"gray\")\n",
    "            plt.title(\"Frame Differencing\")\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            # Background Subtraction\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(fg_mask, cmap=\"gray\")\n",
    "            plt.title(\"Background Subtraction\")\n",
    "            plt.axis(\"off\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Procesar cada video\n",
    "for video in video_paths:\n",
    "    process_video_combined(video)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
