{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ruta al video\n",
    "video_path = \"../videos/video1.mp4\"  # Cambia al video deseado\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_count = 0\n",
    "prev_frame = None\n",
    "num_prev_frame = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Convertir a escala de grises\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Procesar solo en múltiplos de 30\n",
    "    if frame_count % 30 == 0:\n",
    "        if prev_frame is not None:\n",
    "            # Calcular diferencias\n",
    "            diff = cv2.absdiff(prev_frame, frame_gray)\n",
    "            \n",
    "            # Umbralización\n",
    "            _, diff_thresh = cv2.threshold(diff, 70, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "            # Mostrar resultados\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.title(f\"Frame Base {num_prev_frame}\")\n",
    "            plt.imshow(prev_frame, cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.title(f\"Frame Actual {frame_count}\")\n",
    "            plt.imshow(frame_gray, cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.title(\"Diferencia (Umbralizada)\")\n",
    "            plt.imshow(diff_thresh, cmap=\"gray\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "        # Actualizar el frame base\n",
    "        prev_frame = frame_gray\n",
    "        num_prev_frame = frame_count\n",
    "\n",
    "cap.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movimiento detectado en el frame 60 Y PIXELES 24319\n",
      "Movimiento detectado en el frame 90 Y PIXELES 19815\n",
      "Movimiento detectado en el frame 120 Y PIXELES 33342\n",
      "Movimiento detectado en el frame 150 Y PIXELES 18694\n",
      "Movimiento detectado en el frame 180 Y PIXELES 25484\n",
      "Movimiento detectado en el frame 210 Y PIXELES 14419\n",
      "SIN MOVIMIENTO PIXELES 2212\n",
      "SIN MOVIMIENTO PIXELES 240\n",
      "SIN MOVIMIENTO PIXELES 2323\n",
      "SIN MOVIMIENTO PIXELES 1600\n",
      "SIN MOVIMIENTO PIXELES 3134\n",
      "SIN MOVIMIENTO PIXELES 2226\n",
      "SIN MOVIMIENTO PIXELES 2145\n",
      "SIN MOVIMIENTO PIXELES 1251\n",
      "SIN MOVIMIENTO PIXELES 226\n",
      "Movimiento detectado en el frame 510 Y PIXELES 10121\n",
      "Movimiento detectado en el frame 540 Y PIXELES 3352\n",
      "Movimiento detectado en el frame 570 Y PIXELES 17490\n",
      "Movimiento detectado en el frame 600 Y PIXELES 30491\n",
      "Movimiento detectado en el frame 630 Y PIXELES 13850\n",
      "Movimiento detectado en el frame 660 Y PIXELES 3640\n",
      "Movimiento detectado en el frame 690 Y PIXELES 9682\n",
      "Movimiento detectado en el frame 720 Y PIXELES 15144\n",
      "Movimiento detectado en el frame 750 Y PIXELES 37805\n",
      "Movimiento detectado en el frame 780 Y PIXELES 57126\n",
      "Movimiento detectado en el frame 810 Y PIXELES 41445\n",
      "Movimiento detectado en el frame 840 Y PIXELES 69898\n",
      "Movimiento detectado en el frame 870 Y PIXELES 55741\n",
      "Movimiento detectado en el frame 900 Y PIXELES 45860\n",
      "Movimiento detectado en el frame 930 Y PIXELES 84036\n",
      "Movimiento detectado en el frame 960 Y PIXELES 36904\n",
      "Movimiento detectado en el frame 990 Y PIXELES 56453\n",
      "Movimiento detectado en el frame 1020 Y PIXELES 67882\n",
      "Movimiento detectado en el frame 1050 Y PIXELES 28331\n",
      "Movimiento detectado en el frame 1080 Y PIXELES 29502\n",
      "Movimiento detectado en el frame 1110 Y PIXELES 23306\n",
      "Movimiento detectado en el frame 1140 Y PIXELES 13161\n",
      "Pixeles en orden: [226, 240, 1251, 1600, 2145, 2212, 2226, 2323, 3134, 3352, 3640, 9682, 10121, 13161, 13850, 14419, 15144, 17490, 18694, 19815, 23306, 24319, 25484, 28331, 29502, 30491, 33342, 36904, 37805, 41445, 45860, 55741, 56453, 57126, 67882, 69898, 84036]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Ruta al video\n",
    "video_path = \"../videos/video1.mp4\"  # Cambia al video deseado\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_count = 0\n",
    "prev_frame = None\n",
    "\n",
    "# Crear un objeto para detección de movimiento (fondo acumulado)\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Definir un tamaño más pequeño para la ventana\n",
    "resize_width = 640  # Ancho deseado\n",
    "resize_height = 360  # Alto deseado\n",
    "\n",
    "# Reducir la resolución del video para mejorar el rendimiento\n",
    "downscale_factor = 0.5  # Reducción al 50% del tamaño original\n",
    "pixeles = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Reducir la resolución globalmente\n",
    "    frame_resized = cv2.resize(frame, None, fx=downscale_factor, fy=downscale_factor)\n",
    "    \n",
    "    # Convertir a escala de grises\n",
    "    frame_gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Inicializar `diff_thresh` como una matriz vacía para evitar errores\n",
    "    diff_thresh = np.zeros_like(frame_gray)\n",
    "\n",
    "    # Procesar solo en múltiplos de 5 frames para reducir la carga de trabajo\n",
    "    if frame_count % 30 == 0:\n",
    "        if prev_frame is not None:\n",
    "            # Calcular diferencia entre el frame actual y el anterior\n",
    "            diff = cv2.absdiff(prev_frame, frame_gray)\n",
    "            \n",
    "            # Umbralización para obtener la diferencia binaria\n",
    "            _, diff_thresh = cv2.threshold(diff, 90, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Aplicar dilatación para ampliar las áreas detectadas (mejorar contornos)\n",
    "            diff_thresh = cv2.dilate(diff_thresh, None, iterations=2)\n",
    "\n",
    "            # Contar los píxeles cambiados (es decir, detectar el movimiento)\n",
    "            non_zero_count = cv2.countNonZero(diff_thresh)\n",
    "\n",
    "            # Si el número de píxeles cambiados es mayor que un umbral, se detecta movimiento\n",
    "            if non_zero_count > 3200:\n",
    "                print(f\"Movimiento detectado en el frame {frame_count} Y PIXELES {non_zero_count}\")\n",
    "            else:\n",
    "                print(f\"SIN MOVIMIENTO PIXELES {non_zero_count}\")\n",
    "            pixeles.append(non_zero_count)\n",
    "\n",
    "        # Actualizar el frame base\n",
    "        prev_frame = frame_gray\n",
    "\n",
    "    # Redimensionar las imágenes a un tamaño más pequeño para su visualización\n",
    "    diff_resized = cv2.resize(diff_thresh, (resize_width, resize_height))\n",
    "\n",
    "    # Mostrar el video y las diferencias\n",
    "    cv2.imshow('Video Original', frame_resized)\n",
    "    cv2.imshow('Diferencias Umbralizadas', diff_resized)\n",
    "\n",
    "    # Salir con la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Pixeles en orden: {sorted(pixeles)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codigo de funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_differencing(self, fragment_bytes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
